\documentclass[10pt,letterpaper]{article}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{verbatim}
\usepackage{listings}
\usepackage{color}
\usepackage{hyperref}

\usepackage{geometry}
\geometry{letterpaper, margin=1.32in}


\definecolor{mygreen}{rgb}{0,0.5,0}
\definecolor{mygray}{rgb}{0.9,0.9,0.9}
\definecolor{mymauve}{rgb}{0.58,0,0.82}

\lstset{ %
  backgroundcolor=\color{mygray},  % choose the background color; you must add \usepackage{color} or \usepackage{xcolor}
  basicstyle=\footnotesize,        % the size of the fonts that are used for the code
  breakatwhitespace=false,         % sets if automatic breaks should only happen at whitespace
  breaklines=true,                 % sets automatic line breaking
  captionpos=b,                    % sets the caption-position to bottom
  commentstyle=\color{mygreen},    % comment style
  deletekeywords={...},            % if you want to delete keywords from the given language
  escapeinside={\%*}{*)},          % if you want to add LaTeX within your code
  extendedchars=true,              % lets you use non-ASCII characters; for 8-bits encodings only, does not work with UTF-8
  frame=single,	                   % adds a frame around the code
  keepspaces=true,                 % keeps spaces in text, useful for keeping indentation of code (possibly needs columns=flexible)
  keywordstyle=\color{blue},       % keyword style
  language=bash,                 % the language of the code
  otherkeywords={*,...},            % if you want to add more keywords to the set
  numbers=left,                    % where to put the line-numbers; possible values are (none, left, right)
  numbersep=5pt,                   % how far the line-numbers are from the code
  numberstyle=\tiny\color{mygray}, % the style that is used for the line-numbers
  rulecolor=\color{black},         % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. comments (green here))
  showspaces=false,                % show spaces everywhere adding particular underscores; it overrides 'showstringspaces'
  showstringspaces=false,          % underline spaces within strings only
  showtabs=false,                  % show tabs within strings adding particular underscores
  stepnumber=2,                    % the step between two line-numbers. If it's 1, each line will be numbered
  stringstyle=\color{mymauve},     % string literal style
  tabsize=2,	                   % sets default tabsize to 2 spaces
  title=\lstname                   % show the filename of files included with \lstinputlisting; also try caption instead of title
}







%\author{Li Tai Fang}

\title{SomaticSeq Documentation}

\begin{document}

\maketitle



\begin{sloppypar}




\section{Introduction}

SomaticSeq is a flexible workflow that has incorporated multiple somatic mutation callers to obtain a combined call set, and then it uses machine learning to distinguish true mutations from false positives from the call set. We have incorporated six somatic mutation caller: MuTect, VarScan2, JointSNVMix, SomaticSniper, VarDict, and MuSE. You may incorporate some or all of those callers into your own pipeline with SomaticSeq.

The manuscript, An ensemble approach to accurately detect somatic mutations using SomaticSeq, is published in \href{http://dx.doi.org/10.1186/s13059-015-0758-2}{Genome Biology 2015, 16:197}. The SomaticSeq project is located at \href{http://bioinform.github.io/somaticseq/}{\textit{http://bioinform.github.io/somaticseq/}}. The data described in the manuscript is also described at \href{http://bioinform.github.io/somaticseq/data.html}{\textit{http://bioinform.github.io/somaticseq/data.html}}.

SomaticSeq.Wrapper.sh is a bash script that calls a series of scripts to combine the output of the somatic mutation caller(s), after the somatic mutation callers are run. Then, depending on what files are fed to SomaticSeq.Wrapper.sh, it will either train the call set into a classifier, predict high-confidence somatic mutations from the call set, or do nothing. 

\subsection{Dependencies}

\begin{itemize}

\item
All the .py scripts are written in Python 3 (Yes, Python 3. I deserve brownie points from Python developers). Also required are regex, pysam, numpy, and scipy libraries. 

\item
R, plus the ada package in R.

\item
BEDTools

\item
Optional: SnpEff/SnpSift and GATK (only for CombineVariants so the free version is adequate)

\item
dbSNP in VCF format. COSMIC may be needed in the future.

\item
At least one of MuTect/Indelocator, VarScan2, JointSNVMix, SomaticSniper, VarDict, MuSE, or LoFreq. Those are the tools we have incorporated in SomaticSeq. If there are other somatic tools that may be good addition to our list, please make the suggestion to us. 

\end{itemize}



\section{To use SomaticSeq.Wrapper.sh}

The SomaticSeq.Wrapper.sh is a wrapper script that calls a series of programs and procedures. It can be run easily if all the dependencies are met. Some parameters are hard-coded but easily edited. In the next section, we described the workflow in more detail, so you are not dependent on this wrapper script. You can either modify this wrapper script or create your own workflow. 


\subsection{To train data set into a classifier}

To create a trained classifier, ground truth files are required for the data sets. There is also an option to include a list of regions to ignore, where the ground truth is not known in those regions. 

\begin{lstlisting}
# -M/-I/-V/-v/-J/-S/-D/-U are output VCF files from individual callers.
# -i is also optional.
SomaticSeq.Wrapper.sh \
--mutect           MuTect/variants.snp.vcf \
--indelocator      Indelocator/variants.indel.vcf \
--varscan-snv      VarScan2/variants.snp.vcf \
--varscan-indel    VarScan2/variants.indel.vcf \
--jsm              JointSNVMix2/variants.snp.vcf \
--sniper           SomaticSniper/variants.snp.vcf \
--vardict          VarDict/variants.vcf \
--muse             MuSE/variants.snp.vcf \
--lofreq-snv       LoFreq/variants.snp.vcf \
--lofreq-indel     LoFreq/variants.indel.vcf \
--normal-bam       matched_normal.bam \
--tumor-bam        tumor.bam \
--ada-r-script     ada_model_builder.R \
--genome-reference human_b37.fasta \
--cosmic           cosmic.b37.v71.vcf \
--dbsnp            dbSNP.b37.v141.vcf \
--snpeff-dir       $PATH/TO/DIR/snpSift \
--gatk             $PATH/TO/GenomeAnalysisTK.jar \
--ignore-region    ignore.bed \
--truth-snv        truth.snp.vcf \
--truth-indel      truth.indel.vcf \
--output-dir       $OUTPUT_DIR
\end{lstlisting}

SomaticSeq.Wrapper.sh supports any combination of the somatic mutation callers we have incorporated into the workflow, so -M/-I/-V/-v/-J/-S/-D/-U are all optional parameters. SomaticSeq will run based on the output VCFs you have provided. It will train SNV and/or indel if you provide the truth.snp.vcf and/or truth.indel.vcf file(s).




\subsection{To predict somatic mutation based on trained classifiers}

\begin{lstlisting}
# The *.RData files are trained classifier from the training mode.
SomaticSeq.Wrapper.sh \
--mutect           MuTect/variants.snp.vcf \
--indelocator      Indelocator/variants.indel.vcf \
--varscan-snv      VarScan2/variants.snp.vcf \
--varscan-indel    VarScan2/variants.indel.vcf \
--jsm              JointSNVMix2/variants.snp.vcf \
--sniper           SomaticSniper/variants.snp.vcf \
--vardict          VarDict/variants.vcf \
--muse             MuSE/variants.snp.vcf \
--lofreq-snv       LoFreq/variants.snp.vcf \
--lofreq-indel     LoFreq/variants.indel.vcf \
--normal-bam       matched_normal.bam \
--tumor-bam        tumor.bam \
--ada-r-script     ada_model_predictor.R \
--genome-reference human_b37.fasta \
--cosmic           cosmic.b37.v71.vcf \
--dbsnp            dbSNP.b37.v141.vcf \
--snpeff-dir       $PATH/TO/DIR/snpSift \
--gatk             $PATH/TO/GenomeAnalysisTK.jar \
--ignore-region    ignore.bed \
--classifier-snv   sSNV.Classifier.RData \
--classifier-indel sINDEL.Classifier.RData \
--output-dir       $OUTPUT_DIR

\end{lstlisting}





\subsection{To simply create the tab delimited file without doing any machine learning}

Same as the command previously, but not including -R, -C, or -x. 






\section{The step-by-step SomaticSeq Workflow}

We'll describe the workflow here, so you may modify the workflow and/or create your own workflow instead of using the wrapper script described previously. 


\subsection{Combine the call sets}
	We use GATK CombineVariants to combine the VCF files from different callers, although it does not matter what tools are used to merge VCF files. To make them compatible with GATK, the VCF files are modified. A somatic call is also tagged with the tool names, so the combined VCF retains those information. 

\begin{enumerate}

% MuTect and Indelocator
\item 
Modify MuTect and/or Indelocator output VCF files. Somatic calls will be attached the tag 'CGA' in the INFO. 
Since MuTect's output VCF do not always put the tumor and normal samples in the same columns, the script uses samtools extract sample name information from the BAM files, and then determine which column belongs to the normal, and which column belongs to the tumor. 
	
\begin{lstlisting}
# Modify MuTect and Indelocator's output VCF
modify_MuTect.py -infile input.vcf -outfile output.vcf -nbam normal.bam -tbam tumor.bam
	
# If samtools is not in the PATH:
modify_MuTect.py -infile input.vcf -outfile output.vcf -nbam normal.bam -tbam tumor.bam -samtools $PATH/TO/samtools
\end{lstlisting}
	
Alternatively, you can supply the normal and tumor sample names, instead of supplying the BAM files:
\begin{lstlisting}
# Modify MuTect's output VCF
# -type snp for MuTect, and -type indel for Indelocator.
modify_MuTect.py -type snp -infile input.vcf -outfile output.vcf -nsm NormalSampleName -tsm TumorSampleName
\end{lstlisting}

% VarScan2
\item
Modify VarScan's output VCF files to be rigorously concordant to VCF format standard, and to attach the tag 'VarScan2' to somatic calls. 
\begin{lstlisting}
# Do it for both the SNV and indel
modify_VJSD.py -method VarScan2 -infile input.vcf -outfile output.vcf
\end{lstlisting}
	

% JointSNVMix2
\item
JointSNVMix2 does not output VCF files. In our own workflow, we have already converted its text file into a basic VCF file with an 2 awk one-liner, which you may see in the Run\_5\_callers directory, which are:

\begin{lstlisting}
# To avoid text files in the order of terabytes, this awk one-liner keeps entries where the reference is not "N", and the somatic probabilities are at least 0.95.
awk -F "\t" 'NR!=1 && $4!="N" && $10+$11>=0.95'
	
# This awk one-liner converts the text file into a basic VCF file
awk -F "\t" '{print $1 "\t" $2 "\t.\t" $3 "\t" $4 "\t.\t.\tAAAB=" $10 ";AABB=" $11 "\tRD:AD\t" $5 ":" $6 "\t" $7 ":" $8}'


## The actual commands we've used in our workflow:
echo -e '##fileformat=VCFv4.1' > unsorted.vcf
echo -e '##INFO=<ID=AAAB,Number=1,Type=Float,Description="Probability of Joint Genotype AA in Normal and AB in Tumor">' >> unsorted.vcf
echo -e '##INFO=<ID=AABB,Number=1,Type=Float,Description="Probability of Joint Genotype AA in Normal and BB in Tumor">' >> unsorted.vcf
echo -e '##FORMAT=<ID=RD,Number=1,Type=Integer,Description="Depth of reference-supporting bases (reads1)">' >> unsorted.vcf
echo -e '##FORMAT=<ID=AD,Number=1,Type=Integer,Description="Depth of variant-supporting bases (reads2)">' >> unsorted.vcf
echo -e '#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\tFORMAT\tNORMAL\tTUMOR' >> unsorted.vcf

python $PATH/TO/jsm.py classify joint_snv_mix_two genome.GRCh37.fa normal.bam tumor.bam trained.parameter.cfg /dev/stdout | awk -F "\t" 'NR!=1 && $4!="N" && $10+$11>0.95' | awk -F "\t" '{print $1 "\t" $2 "\t.\t" $3 "\t" $4 "\t.\t.\tAAAB=" $10 ";AABB=" $11 "\tRD:AD\t" $5 ":" $6 "\t" $7 ":" $8}' >> unsorted.vcf
\end{lstlisting}
	
After that, you'll also want to sort the VCF file. Now, to modify that basic VCF into something that will be compatible with other VCF files under GATK CombineVariants:
	
\begin{lstlisting}
modify_VJSD.py -method JointSNVMix2 -infile input.vcf -outfile output.vcf
\end{lstlisting}

% SomaticSniper:
\item	
Modify SomaticSniper's output:
	
\begin{lstlisting}
modify_VJSD.py -method SomaticSniper -infile input.vcf -outfile output.vcf
\end{lstlisting}
	
	
% VarDict
\item	
VarDict has both SNV and indel, plus some other variants in the same VCF file. Our script will create two files, one for SNV and one for indel, while everything else is ignored for now. By default, LikelySomatic/StrongSomatic and PASS calls will be labeled VarDict. However, in our SomaticSeq paper, based on our experience in DREAM Challenge, we implemented two custom filters to relax the VarDict tagging criteria. 
	
\begin{lstlisting}
# Default VarDict tagging criteria, only PASS (and Likely or Strong Somatic):
modify_VJSD.py -method VarDict -infile intput.vcf -outfile output.vcf
	
# When running VarDict, if var2vcf_paired.pl is used to generate the VCF file, you may relax the tagging criteria with -filter paired
modify_VJSD.py -method VarDict -infile intput.vcf -outfile output.vcf -filter paired
	
# When running VarDict, if var2vcf_somatic.pl is used to generate the VCF file, you may relax the tagging criteria with -filter somatic
modify_VJSD.py -method VarDict -infile intput.vcf -outfile output.vcf -filter somatic
\end{lstlisting}
	

In the SomaticSeq paper, -filter somatic was used because var2vcf\_somatic.pl was used to generate VarDict's VCF files. In the SomaticSeq.Wrapper.sh script, however, -filter paired is used because VarDict authors have since recommended var2vcf\_paired.pl script to create the VCF files. While there are some differences (different stringencies in some filters) in what VarDict labels as PASS between the somatic.pl and paired.pl scripts, the difference is miniscule after applying our custom filter (which relaxes the filter, resulting in a difference about 5 calls out of 15,000). 

The output files will be snp.output.vcf and indel.output.vcf. 


% MuSE
\item
MuSE was not a part of our analysis in the SomaticSeq paper. We have implemented it later. 
	
\begin{lstlisting}
modify_VJSD.py -method MuSE -infile input.vcf -outfile output.vcf
\end{lstlisting}

% GATK CombineVariants
\item
Finally, with the VCF files modified, you may combine them with GATK CombineVariants: one for SNV and one for indel separately. There is no particular reason to use GATK CombineVariants. Other combiners should also work. The only useful thing here is to combine the calls, and preserve the tags we have written into each individual VCF file's INFO. 
	
\begin{lstlisting}
# Combine the VCF files for SNV. Any or all of the VCF files may be present.
# -nt 12 means to use 12 threads in parallel
java -jar $PATH/TO/GenomeAnalysisTK.jar -T CombineVariants -R genome.GRCh37.fa -nt 12 --setKey null --genotypemergeoption UNSORTED -V mutect.vcf -V varscan.snp.vcf -V jointsnvmix.vcf -V snp.vardict.vcf -V muse.vcf --out CombineVariants.snp.vcf
java -jar $PATH/TO/GenomeAnalysisTK.jar -T CombineVariants -R genome.GRCh37.fa -nt 12 --setKey null --genotypemergeoption UNSORTED -V indelocator.vcf -V varscan.snp.vcf -V indel.vardict.vcf --out CombineVariants.indel.vcf
\end{lstlisting}
	
	
% SnpSift and SnpEff:
\item
Use SnpSift to add dbSNP information to the VCF file, since dbSNP information is part of training feature set. Right now, we do not use COSMIC or functional annotation as a part of training feature, but we do have them in the workflow for "future-proofing." We may decide to use those features in the future when we have better data sets for training. 
	
\begin{lstlisting}
# SNV
java -jar $PATH/TO/SnpSift.jar annotate dbSNP141.vcf CombineVariants.snp.vcf | java -jar $PATH/TO/SnpSift.jar annotate COSMIC.vcf - | java -jar $PATH/TO/snpEff.jar GRCh37.75 - > EFF.COSMIC.dbSNP.CombineVariants.snp.vcf

# INDEL
java -jar $PATH/TO/SnpSift.jar annotate dbSNP141.vcf CombineVariants.indel.vcf | java -jar $PATH/TO/SnpSift.jar annotate COSMIC.vcf - | java -jar $PATH/TO/snpEff.jar GRCh37.75 - > EFF.COSMIC.dbSNP.CombineVariants.indel.vcf
\end{lstlisting}
	

		
	
% Run the original OncoRank script
\item
This procedure annotates the caller consensus by putting the tool names into the SOURCES in the INFO. You should also use -mincaller 1 to only keep calls where at least one caller has called it somatic. Vast majority of the calls in the previous merged VCF files were REJECT or GERMLINE calls, and may run out of memory in model training if all are included. It also does some rudimentary variant scoring, but the scoring is not utilized in SomaticSeq. You need to run it once for SNV and once for indel. 
	
\begin{lstlisting}
# Use -tools to indicate what call sets were combined. CGA=MuTect/Indelocator
# In this one, 6 tools were used for SNV
score_Somatic.Variants.py -tools CGA VarScan2 JointSNVMix2 SomaticSniper VarDict MuSE -infile EFF.COSMIC.dbSNP.CombineVariants.snp.vcf -mincaller 1 -outfile BINA_somatic.snp.vcf
	
# 3 tools for indel
score_Somatic.Variants.py -tools CGA VarScan2 VarDict -infile EFF.COSMIC.dbSNP.CombineVariants.indel.vcf -mincaller 1 -outfile BINA_somatic.indel.vcf
\end{lstlisting}
	
And now, the call sets are combined into one VCF file for SNV and one VCF file for indel.


\end{enumerate}





\subsection{For model training: process and annotate the VCF files (union of call sets)}

This step may be needed for model training. The workflow in SomaticSeq.Wrapper.sh allows for an exclusion region, e.g., we don't care for anything inside the exclusion region, typically because we don't know if a call made in this region is a false positive or true positive. DREAM Challenge had exclusion regions, e.g., blacklisted regions, etc. Alternatively, you can use an inclusion region instead, to obtain a list of variants that you have done experimental validation, so you know which ones are true mutations and which ones are false positives, to facilitate model training. 
	
\begin{lstlisting}
# In the DREAM_Stage_3 directory, we have included an exclusion region BED file as an example
# This command uses BEDtools to rid of all calls in the exclusion region
intersectBed -header -a BINA_somatic.snp.vcf -b ignore -v > somatic.snp.processed.vcf
intersectBed -header -a BINA_somatic.indel.vcf -b ignore -v > somatic.indel.processed.vcf
	
\end{lstlisting}



\subsection{Convert the VCF file, annotated or otherwise, into a tab separated file}
This script works for all VCF files. It extracts information from BAM files as well as VCF files created by the individual callers. If the ground truth VCF file is included, a called variant will be annotated as a true positive, and everything will be annotated as a false positive. 
	
	
\begin{lstlisting}
# -mutect / -sniper / -varscan / -jsm / -vardict / -muse are optional. 
# -truth is also optional, but it is needed to annotate ground truth information, and is required for model training.
SSeq_merged.vcf2tsv.py -ref genome.GRCh37.fa -myvcf somatic.snp.processed.vcf -truth Ground.truth.snp.vcf -mutect MuTect/variants.snp.vcf.gz -varscan VarScan2/variants.snp.vcf -jsm JSM2/variants.vcf -sniper SomaticSniper/variants.vcf -vardict VarDict/snp.variants.vcf -tbam tumor.bam -nbam normal.bam -outfile Ensemble.sSNV.tsv
\end{lstlisting}


That was for SNV, and indel is almost the same thing. After version 2.1, we have replaced all information from SAMtools and HaplotypeCaller with information directly from the BAM files. The accuracy differences are negligible with significant improvement in usability and resource requirement.

\begin{lstlisting}
# INDEL:
SSeq_merged.vcf2tsv.py -ref genome.GRCh37.fa -myvcf somatic.indel.processed.vcf -truth Ground.truth.indel.vcf -varscan VarScan2/variants.snp.vcf -vardict VarDict/indel.variants.vcf -tbam tumor.bam -nbam normal.bam -outfile Ensemble.sINDEL.tsv
\end{lstlisting}


At the end of this, Ensemble.sSNV.tsv and Ensemble.sINDEL.tsv are created. 



\subsection{Model Training or Mutation Prediction}

You can use Ensemble.sSNV.tsv and Ensemble.sINDEL.tsv files either for model training (provided that their mutation status is annotated with 0 or 1) or mutation prediction. This is done with stochastic boosting algorithm we have implemented in R. 
	
Model training:
\begin{lstlisting}
# Training:
R --no-save --args Ensemble.sSNV.tsv < ada_model_builder.R
R --no-save --args Ensemble.sINDEL.tsv < ada_model_builder.R
\end{lstlisting}
	
Ensemble.sSNV.tsv.Classifier.RData and Ensemble.sINDEL.tsv.Classifier.RData will be created from model training.
	

Mutation prediction:
	
\begin{lstlisting}
# Mutation prediction:
R --no-save --args Ensemble.sSNV.tsv.Classifier.RData Ensemble.sSNV.tsv Trained.sSNV.tsv < ada_model_predictor.R
R --no-save --args Ensemble.sINDEL.tsv.Classifier.RData Ensemble.sINDEL.tsv Trained.sINDEL.tsv < ada_model_predictor.R
\end{lstlisting}

	
After mutation prediction, if you feel like it, you may convert Trained.sSNV.tsv and Trained.sINDEL.tsv into VCF files.

\begin{lstlisting}
# Probability above 0.7 labeled PASS (-pass 0.7), and between 0.1 and 0.7 labeled LowQual (-low 0.1):
# Use -all to include REJECT calls in the VCF file
# Use -phred to convert probability values (between 0 to 1) into Phred scale in the QUAL column in the VCF file
# Use -tools to list the individual tools used. Accepted tools are CGA (for MuTect/Indelocator), VarScan2, JointSNVMix2, SomaticSniper, VarDict, MuSE, and/or LoFreq. 
SSeq_tsv2vcf.py -tsv Trained.sSNV.tsv -vcf Trained.sSNV.vcf -pass 0.7 -low 0.1 -tools CGA VarScan2 JointSNVMix2 SomaticSniper VarDict -all -phred
SSeq_tsv2vcf.py -tsv Trained.sINDEL.tsv -vcf Trained.sINDEL.vcf -pass 0.7 -low 0.1 -tools CGA VarScan2 VarDict -all -phred
\end{lstlisting}







\section{Release Notes}

Make sure training and prediction use the same version.

\subsection{Version 1.0}
Version used to generate data in the manuscript and \href{https://www.synapse.org/#!Synapse:syn312572/wiki/72943}{Stage 5 of the ICGC-TCGA DREAM Somatic Mutation Challenge}, where SomaticSeq's results were \#1 for INDEL and \#2 for SNV. 

In the original manuscript, VarDict's var2vcf\_somatic.pl script was used to generate VarDict VCFs, and subsequently ``-filter somatic'' was used for SSeq\_merged.vcf2tsv.py. Since then (including DREAM Challenge Stage 5), VarDict recommends var2vcf\_paired.pl over var2vcf\_somatic.pl, and subsequently ``-filter paired'' was used for SSeq\_merged.vcf2tsv.py. The difference in SomaticSeq results, however, is pretty much negligible. 

\subsection{Version 1.1}
Automated the SomaticSeq.Wrapper.sh script for both training and prediction mode. No change to any algorithm. 

\subsection{Version 1.2}
Have implemented the following improvement, mostly for indels:

\begin{itemize}
 
  \item 
  SSeq\_merged.vcf2tsv.py can now accept pileup files to extract read depth and DP4 (reference forward, reference reverse, alternate forward, and alternate reverse) information (mainly for indels). Previously, that information can only be extracted from SAMtools VCF. Since the SAMtools or HaplotypeCaller generated VCFs hardly contain any indel information, this option improves the indel model. The SomaticSeq.Wrapper.sh script is modified accordingly.
 
  \item
  Extract mapping quality (MQ) from VarDict output if this information cannot be found in SAMtools VCF (also mostly benefits the indel model). 
 
  \item
  Indel length now positive for insertions and negative for deletions, instead of using the absolute value previously. 
 
 
\end{itemize}




\subsection{Version 2.0}

\begin{itemize}
  \item
  Removed dependencies for SAMtools and HaplotypeCaller during feature extraction. SSeq\_merged.vcf2tsv.py extracts those information (plus more) directly from BAM files.

  \item
  Allow not only VCF file, but also BED file or a list of chromosome coordinate as input format for SSeq\_merged.vcf2tsv.py, i.e., use -mybed or -mypos instead of -myvcf. 

  \item
  Instead of a separate step to annotate ground truth, that can be done directly by SSeq\_merged.vcf2tsv.py.

  \item
  SSeq\_merged.vcf2tsv.py can annotate dbSNP and COSMIC information directly if BED file or a list of chromosome coordinates are used as input in lieu of an annotated VCF file. 

  \item
  Consolidated feature sets, e.g., removed some redundant feature sets coming from different resources.
\end{itemize}


\subsection{Version 2.0.2}

\begin{itemize}
  \item
  Used getopt to replace getopts in the SomaticSeq.Wrapper.sh script to allow long options. 
  
\end{itemize}




\section{To do: planned improvement}

\begin{itemize}

  \item
  Develop a version for deep sequencing cfDNA/ctDNA. 
  
  \item
  Dockerize SomaticSeq

\end{itemize}










\section{Known issues}

\begin{itemize}

  \item
  Some older versions of GATK seem to have problem with FIFO used in the SomaticSeq script (i.e., we had problem with GATK version 2014.1-2.8.1), so we recommend at least version version 2014.4-2 or later.

\end{itemize}






\section{Contact Us}
For suggestions, bug reports, or technical support, please email \href{mailto:li_tai.fang@bina.roche.com}{li\_tai.fang@bina.roche.com}.


\end{sloppypar}
\end{document}